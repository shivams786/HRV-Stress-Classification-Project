{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RHMbPh7Gx2oi",
        "outputId": "2f8708ba-d949-419d-d3ae-c0b300899f20",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First few rows of the dataset:\n",
            "   63.0  1.0  1.0.1  145.0  233.0  1.0.2  2.0  150.0  0.0  2.3  3.0 0.0.1  \\\n",
            "0  67.0  1.0    4.0  160.0  286.0    0.0  2.0  108.0  1.0  1.5  2.0   3.0   \n",
            "1  67.0  1.0    4.0  120.0  229.0    0.0  2.0  129.0  1.0  2.6  2.0   2.0   \n",
            "2  37.0  1.0    3.0  130.0  250.0    0.0  0.0  187.0  0.0  3.5  3.0   0.0   \n",
            "3  41.0  0.0    2.0  130.0  204.0    0.0  2.0  172.0  0.0  1.4  1.0   0.0   \n",
            "4  56.0  1.0    2.0  120.0  236.0    0.0  0.0  178.0  0.0  0.8  1.0   0.0   \n",
            "\n",
            "   6.0  0  \n",
            "0  3.0  2  \n",
            "1  7.0  1  \n",
            "2  3.0  0  \n",
            "3  3.0  0  \n",
            "4  3.0  0  \n",
            "\n",
            "Cross-validation accuracy scores: [0.54098361 0.50819672 0.6        0.68333333 0.55      ]\n",
            "Mean cross-validation accuracy: 0.5765027322404371\n",
            "\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.89      0.90       163\n",
            "           1       0.69      0.53      0.60        55\n",
            "           2       0.76      0.86      0.81        36\n",
            "           3       0.76      0.83      0.79        35\n",
            "           4       0.62      1.00      0.76        13\n",
            "\n",
            "    accuracy                           0.82       302\n",
            "   macro avg       0.75      0.82      0.77       302\n",
            "weighted avg       0.82      0.82      0.81       302\n",
            "\n",
            "\n",
            "Accuracy Score on the dataset: 0.8178807947019867\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "\n",
        "# Step 1: Load the new dataset\n",
        "\n",
        "# Load the dataset (assuming it's a CSV file, update if it's a different format)\n",
        "df = pd.read_csv(\"/content/processed.cleveland.data\")  # header=None if no column headers in the file\n",
        "\n",
        "# Step 2: Check the first few rows to understand the structure of the data\n",
        "print(\"First few rows of the dataset:\")\n",
        "print(df.head())\n",
        "\n",
        "# Step 3: Handle the dataset columns (assuming columns are unnamed, we will name them)\n",
        "# Column names can be adjusted depending on the dataset's actual structure\n",
        "columns = ['age', 'sex', 'cp', 'trestbps', 'chol', 'fbs', 'restecg', 'thalach', 'exang', 'oldpeak', 'slope', 'ca', 'thal', 'target']\n",
        "df.columns = columns  # Rename the columns\n",
        "\n",
        "# Step 4: Replace '?' with NaN and handle missing values\n",
        "df.replace('?', np.nan, inplace=True)\n",
        "df = df.apply(pd.to_numeric, errors='coerce')  # Convert to numeric values, coercing invalid entries to NaN\n",
        "df.fillna(df.median(), inplace=True)  # Impute missing values with the median of each column\n",
        "\n",
        "# Step 5: Feature selection and preprocessing\n",
        "target_column = 'target'  # This is the target column for classification\n",
        "\n",
        "# Separate features and target\n",
        "X = df.drop(target_column, axis=1)\n",
        "y = df[target_column]\n",
        "\n",
        "# Step 6: Data scaling (Standardizing the features)\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Step 7: Handle Class Imbalance (if necessary)\n",
        "classes = np.unique(y)  # This will extract unique classes from the target column\n",
        "class_weights = compute_class_weight('balanced', classes=classes, y=y)\n",
        "class_weight_dict = dict(zip(classes, class_weights))\n",
        "\n",
        "# Step 8: Random Forest Classifier with Regularization\n",
        "# Adjust the hyperparameters to prevent overfitting\n",
        "model = RandomForestClassifier(\n",
        "    random_state=42,\n",
        "    class_weight=class_weight_dict,\n",
        "    n_estimators=50,  # Reduced number of trees\n",
        "    max_depth=5,  # Reduced depth of trees\n",
        "    min_samples_split=10,  # Increased min samples per split\n",
        "    min_samples_leaf=5,  # Increased min samples per leaf\n",
        "    max_features='sqrt'  # Limit number of features per split\n",
        ")\n",
        "\n",
        "# Use Cross-validation to evaluate the model (StratifiedKFold ensures balanced class distribution in each fold)\n",
        "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "cv_scores = cross_val_score(model, X_scaled, y, cv=cv, scoring='accuracy')\n",
        "\n",
        "print(f\"\\nCross-validation accuracy scores: {cv_scores}\")\n",
        "print(f\"Mean cross-validation accuracy: {cv_scores.mean()}\")\n",
        "\n",
        "# Step 9: Train the model on the entire dataset\n",
        "model.fit(X_scaled, y)\n",
        "\n",
        "# Step 10: Make predictions\n",
        "y_pred = model.predict(X_scaled)\n",
        "\n",
        "# Step 11: Evaluate the model\n",
        "print(\"\\nClassification Report:\")\n",
        "print(classification_report(y, y_pred))\n",
        "\n",
        "print(\"\\nAccuracy Score on the dataset:\", accuracy_score(y, y_pred))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section"
      ],
      "metadata": {
        "id": "swUGvAh3Hxov"
      }
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}